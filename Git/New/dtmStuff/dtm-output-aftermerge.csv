Start state index,Action index,Finish state index,Probability for Triple,Reward for Triple,Prob x Reward
0,2,14,1.0,1.0,1.0
1,2,32,1.0,2.0,2.0
2,2,26,1.0,1.0,1.0
3,2,42,1.0,1.0,1.0
4,0,38,1.0,1.0,1.0
5,2,22,1.0,1.0,1.0
6,0,23,1.0,1.0,1.0
8,0,34,1.0,1.0,1.0
9,0,1,1.0,1.8000000000000003,1.8000000000000003
10,2,8,1.0,1.0,1.0
11,2,16,1.0,1.0,1.0
12,2,19,1.0,1.0,1.0
13,2,10,1.0,1.0,1.0
14,0,43,1.0,1.0,1.0
15,0,39,1.0,1.0,1.0
16,2,30,1.0,1.0,1.0
17,2,21,1.0,1.0,1.0
18,0,18,1.0,0.5,0.5
18,2,15,1.0,0.5,0.5
19,2,18,1.0,1.0,1.0
20,0,6,1.0,1.0,1.0
21,0,27,1.0,1.0,1.0
23,2,41,1.0,1.0,1.0
24,2,20,1.0,1.0,1.0
25,0,5,1.0,1.0,1.0
26,0,37,1.0,1.0,1.0
27,0,13,1.0,1.0,1.0
28,2,17,0.2,1.0,0.2
28,2,24,0.2,1.0,0.2
28,2,36,0.2,1.0,0.2
28,2,40,0.4,1.0,0.4
29,0,11,1.0,1.0,1.0
30,0,12,1.0,1.0,1.0
31,2,2,1.0,1.0,1.0
32,2,4,0.5,1.0,0.5
32,2,33,0.5,1.0,0.5
33,0,7,1.0,1.0,1.0
34,2,25,1.0,1.0,1.0
35,2,14,1.0,1.0,1.0
36,2,29,1.0,1.0,1.0
40,0,0,0.5,1.0,0.5
40,0,35,0.5,1.0,0.5
41,0,3,1.0,0.9999999999999993,0.9999999999999993
42,0,42,1.0,0.25000000000000044,0.25000000000000044
42,2,31,1.0,0.5,0.5
43,2,9,1.0,1.0,1.0
Decision probabilities --
State index,Action index,P(A|S)
0,2,1.0
1,2,1.0
2,2,1.0
3,2,1.0
4,0,1.0
5,2,1.0
6,0,1.0
8,0,1.0
9,0,1.0
10,2,1.0
11,2,1.0
12,2,1.0
13,2,1.0
14,0,1.0
15,0,1.0
16,2,1.0
17,2,1.0
18,0,0.5
18,2,0.5
19,2,1.0
20,0,1.0
21,0,1.0
23,2,1.0
24,2,1.0
25,0,1.0
26,0,1.0
27,0,1.0
28,2,1.0
29,0,1.0
30,0,1.0
31,2,1.0
32,2,1.0
33,0,1.0
34,2,1.0
35,2,1.0
36,2,1.0
40,0,1.0
41,0,0.9999999999999993
42,0,0.25000000000000044
42,2,0.5
43,2,1.0
Lower bound trajectory value for a =,9.200000000000001
Upper bound trajectory value for b =,9.200000000000001
Lower bound trajectory value for b =,0.0
Upper bound trajectory value for c =,0.0
Lower bound trajectory value for c =,0.0
Upper bound trajectory value for d =,0.0
Report for trajectory list =,Target trajectories
Trajectory #,Trajectory probability,Reward sum,Expected linear reward with discount,Trajectory probability x Reward sum,Trajectory
1,0.1,10.8,3.7483417600000015,1.08,"[28, 2, 40, 0, 0, 2, 14, 0, 43, 2, 9, 0, 1, 2, 32, 2, 4, 0, 38]"
2,0.2,10.0,3.619508326400001,2.0,"[28, 2, 36, 2, 29, 0, 11, 2, 16, 2, 30, 0, 12, 2, 19, 2, 18, 0, 18, 2, 15, 0, 39]"
3,0.1,10.8,3.7483417600000015,1.08,"[28, 2, 40, 0, 35, 2, 14, 0, 43, 2, 9, 0, 1, 2, 32, 2, 33, 0, 7]"
4,0.2,10.75,3.6152301363200006,2.15,"[28, 2, 24, 2, 20, 0, 6, 0, 23, 2, 41, 0, 3, 2, 42, 0, 42, 2, 31, 2, 2, 2, 26, 0, 37]"
5,0.2,10.0,3.6631290880000007,2.0,"[28, 2, 17, 2, 21, 0, 27, 0, 13, 2, 10, 2, 8, 0, 34, 2, 25, 0, 5, 2, 22]"
Report for trajectory list =,Target neighboring trajectories
Trajectory #,Trajectory probability,Reward sum,Expected linear reward with discount,Trajectory probability x Reward sum,Trajectory
1,0.2,9.5,3.565821235200001,1.9000000000000001,"[28, 2, 36, 2, 29, 0, 11, 2, 16, 2, 30, 0, 12, 2, 19, 2, 18, 0, 18, 0, 18, 2, 15]"
2,0.1,10.8,3.7483417600000015,1.08,"[28, 2, 40, 0, 35, 2, 14, 0, 43, 2, 9, 0, 1, 2, 32, 2, 4, 0, 38]"
3,0.2,10.0,3.506178232320001,2.0,"[28, 2, 24, 2, 20, 0, 6, 0, 23, 2, 41, 0, 3, 2, 42, 0, 42, 0, 42, 2, 31, 2, 2, 2, 26]"
4,0.1,10.8,3.7483417600000015,1.08,"[28, 2, 40, 0, 0, 2, 14, 0, 43, 2, 9, 0, 1, 2, 32, 2, 33, 0, 7]"
5,0.2,9.5,3.565821235200001,1.9000000000000001,"[28, 2, 36, 2, 29, 0, 11, 2, 16, 2, 30, 0, 12, 2, 19, 2, 18, 0, 18, 0, 18, 0, 18]"
Report for trajectory list =,Others neighboring trajectories
Trajectory #,Trajectory probability,Reward sum,Expected linear reward with discount,Trajectory probability x Reward sum,Trajectory
Report for trajectory list =,Others trajectories
Trajectory #,Trajectory probability,Reward sum,Expected linear reward with discount,Trajectory probability x Reward sum,Trajectory
